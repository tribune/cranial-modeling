{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train an LDA model\n",
    "\n",
    "- download data from ..\n",
    "- use spacy to tokenize and leave only nouns\n",
    "- train a gensim dictinoary\n",
    "- train gensim LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "csv.field_size_limit(100000000)\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "from toolz.functoolz import compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn on logging to see progress\n",
    "os.environ['CRANIAL_LOGLEVEL'] = \"INFO\"\n",
    "\n",
    "from cranial.re_iter import ReMap, ReChain, ReFilter, Progress, ReBatch, DiskCache, ReZip\n",
    "from cranial.models.spacy_tokenizers import SpacyWrapper\n",
    "from cranial.models.gensim_models import GensimDictionary, GensimTFIDF, GensimLDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a data files list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/articles1.csv', 'data/articles2.csv', 'data/articles3.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob('data/*.csv')\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check the header "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'id', 'title', 'publication', 'author', 'date', 'year', 'month', 'url', 'content']\n"
     ]
    }
   ],
   "source": [
    "with open(files[0]) as f:\n",
    "    print(f.readline().strip().split(','))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(fname):\n",
    "    \"\"\"Read a csv file and output each row as a dictionary\"\"\"\n",
    "    with open(fname) as f:\n",
    "        reader = csv.reader(f)\n",
    "        header = next(reader)\n",
    "        for line in reader:\n",
    "            yield dict(zip(header, line))\n",
    "            \n",
    "def to_tokens_list(doc):\n",
    "    \"\"\"Take only nouns, remove stop words, and lemmatize\"\"\"\n",
    "    return [t.lemma_ for t in doc if t.pos_ == 'NOUN' and not t.is_stop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate spacy model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start spacy model with in and out fields defined since each data point is a dictionary and we need to tokenize only text in \"content\" field.\n",
    "\n",
    "Alternatively, if each data point was a text, then in and out fields could be left as None.\n",
    "```python\n",
    "spacy_tokenizer = SpacyWrapper(lang='en', batch_size=1000)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-05T17:31:52PDT - spacy_tokenizers.py - INFO - loading spacy...\n"
     ]
    }
   ],
   "source": [
    "spacy_tokenizer = SpacyWrapper(lang='en', in_field='content', out_field='doc', batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define transformations of iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file names tranformed into iterators of rows in each file\n",
    "out = ReMap(read_csv, files)\n",
    "\n",
    "# all individual rows iterators are chained together\n",
    "records = ReChain(out, name='chain rows from files')\n",
    "\n",
    "# spacy creates a 'doc' key in each tranformed row wich containes spacy-parsed document\n",
    "out = spacy_tokenizer.itransform(records)\n",
    "\n",
    "# print out how many rows has been tranformed\n",
    "out = Progress(out, max_period=5000, name='OUT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert into a list of tokens\n",
    "tokens = ReMap(lambda rec: to_tokens_list(rec['doc']), out)\n",
    "\n",
    "# store each row to disk to avoid upstream re-runs (spacy is computationally expensive)\n",
    "tokens = DiskCache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate gensim dictionary and train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-05T17:31:53PDT - gensim_models.py - INFO - Init gensim dictionary with params:\n",
      "{'no_below_raw': 0, 'no_above_raw': 1.0, 'max_n_raw': 100000, 'no_below': 10, 'no_above': 0.1, 'max_n': 10000, 'dict_filter_every': 50000}\n",
      "2018-07-05T17:31:53PDT - gensim_models.py - INFO - Building gensim dictionary...\n",
      "2018-07-05T17:31:53PDT - re_iter.py - INFO - Disk Cache:\tStart iter number 1\n",
      "2018-07-05T17:31:53PDT - re_iter.py - INFO - Disk Cache:\tSaving iterable to 4476141b-8009-4d46-a7c7-d8707b251d1c\n",
      "2018-07-05T17:31:53PDT - re_iter.py - INFO - reMap:\tStart iter number 1\n",
      "2018-07-05T17:31:53PDT - re_iter.py - INFO - OUT:\tStart iter number 1\n",
      "2018-07-05T17:31:53PDT - re_iter.py - INFO - reGenerate:\tStart iter number 1\n",
      "2018-07-05T17:31:53PDT - re_iter.py - INFO - chain rows from files:\tStart iter number 1\n",
      "2018-07-05T17:31:53PDT - re_iter.py - INFO - reMap:\tStart iter number 1\n",
      "2018-07-05T17:31:53PDT - re_iter.py - INFO - chain rows from files:\tStart iter number 2\n",
      "2018-07-05T17:31:53PDT - re_iter.py - INFO - reMap:\tStart iter number 2\n",
      "2018-07-05T17:35:44PDT - re_iter.py - INFO - OUT yielded 1 items\n",
      "2018-07-05T17:35:44PDT - re_iter.py - INFO - OUT yielded 2 items\n",
      "2018-07-05T17:35:44PDT - re_iter.py - INFO - OUT yielded 5 items\n",
      "2018-07-05T17:35:44PDT - re_iter.py - INFO - OUT yielded 10 items\n",
      "2018-07-05T17:35:44PDT - re_iter.py - INFO - OUT yielded 20 items\n",
      "2018-07-05T17:35:44PDT - re_iter.py - INFO - OUT yielded 50 items\n",
      "2018-07-05T17:35:45PDT - re_iter.py - INFO - OUT yielded 100 items\n",
      "2018-07-05T17:35:45PDT - re_iter.py - INFO - OUT yielded 200 items\n",
      "2018-07-05T17:35:45PDT - re_iter.py - INFO - OUT yielded 500 items\n",
      "2018-07-05T17:35:45PDT - re_iter.py - INFO - OUT yielded 1000 items\n",
      "2018-07-05T17:39:43PDT - re_iter.py - INFO - OUT yielded 2000 items\n",
      "2018-07-05T17:51:57PDT - re_iter.py - INFO - OUT yielded 5000 items.\tspeed now 4.15\tEMA speed 4.15\n",
      "2018-07-05T18:07:02PDT - re_iter.py - INFO - OUT yielded 10000 items.\tspeed now 5.52\tEMA speed 4.29\n",
      "2018-07-05T18:15:17PDT - re_iter.py - INFO - OUT yielded 15000 items.\tspeed now 10.09\tEMA speed 4.87\n",
      "2018-07-05T18:24:00PDT - re_iter.py - INFO - OUT yielded 20000 items.\tspeed now 9.57\tEMA speed 5.34\n",
      "2018-07-05T18:32:45PDT - re_iter.py - INFO - OUT yielded 25000 items.\tspeed now 9.52\tEMA speed 5.76\n",
      "2018-07-05T18:41:40PDT - re_iter.py - INFO - OUT yielded 30000 items.\tspeed now 9.35\tEMA speed 6.12\n",
      "2018-07-05T18:53:11PDT - re_iter.py - INFO - OUT yielded 35000 items.\tspeed now 7.24\tEMA speed 6.23\n",
      "2018-07-05T19:05:22PDT - re_iter.py - INFO - OUT yielded 40000 items.\tspeed now 6.84\tEMA speed 6.29\n",
      "2018-07-05T19:16:09PDT - re_iter.py - INFO - OUT yielded 45000 items.\tspeed now 7.72\tEMA speed 6.43\n",
      "2018-07-05T19:24:11PDT - re_iter.py - INFO - OUT yielded 50000 items.\tspeed now 10.38\tEMA speed 6.83\n",
      "2018-07-05T19:29:05PDT - gensim_models.py - INFO - Current dictionary: Dictionary(58696 unique tokens: ['access', 'administration', 'advocate', 'ally', 'appeal']...)\n",
      "2018-07-05T19:29:05PDT - gensim_models.py - INFO - Filtering at 50000 documents\n",
      "2018-07-05T19:29:06PDT - gensim_models.py - INFO - Now dictionary: Dictionary(58696 unique tokens: ['access', 'administration', 'advocate', 'ally', 'appeal']...)\n",
      "2018-07-05T19:49:11PDT - re_iter.py - INFO - OUT yielded 55000 items.\tspeed now 3.33\tEMA speed 6.48\n",
      "2018-07-05T20:02:56PDT - re_iter.py - INFO - OUT yielded 60000 items.\tspeed now 6.07\tEMA speed 6.44\n",
      "2018-07-05T20:10:20PDT - re_iter.py - INFO - OUT yielded 65000 items.\tspeed now 11.26\tEMA speed 6.92\n",
      "2018-07-05T20:21:32PDT - re_iter.py - INFO - OUT yielded 70000 items.\tspeed now 7.43\tEMA speed 6.97\n",
      "2018-07-05T20:37:15PDT - re_iter.py - INFO - OUT yielded 75000 items.\tspeed now 5.31\tEMA speed 6.80\n",
      "2018-07-05T20:49:12PDT - re_iter.py - INFO - OUT yielded 80000 items.\tspeed now 6.97\tEMA speed 6.82\n",
      "2018-07-05T20:56:43PDT - re_iter.py - INFO - OUT yielded 85000 items.\tspeed now 11.10\tEMA speed 7.25\n",
      "2018-07-05T21:04:20PDT - re_iter.py - INFO - OUT yielded 90000 items.\tspeed now 10.93\tEMA speed 7.62\n",
      "2018-07-05T21:12:12PDT - re_iter.py - INFO - OUT yielded 95000 items.\tspeed now 10.60\tEMA speed 7.91\n",
      "2018-07-05T21:27:23PDT - re_iter.py - INFO - OUT yielded 100000 items.\tspeed now 5.49\tEMA speed 7.67\n",
      "2018-07-05T21:30:26PDT - gensim_models.py - INFO - Current dictionary: Dictionary(88609 unique tokens: ['access', 'administration', 'advocate', 'ally', 'appeal']...)\n",
      "2018-07-05T21:30:26PDT - gensim_models.py - INFO - Filtering at 100000 documents\n",
      "2018-07-05T21:30:27PDT - gensim_models.py - INFO - Now dictionary: Dictionary(88609 unique tokens: ['access', 'administration', 'advocate', 'ally', 'appeal']...)\n",
      "2018-07-05T21:42:11PDT - re_iter.py - INFO - OUT yielded 105000 items.\tspeed now 5.62\tEMA speed 7.47\n",
      "2018-07-05T21:55:11PDT - re_iter.py - INFO - OUT yielded 110000 items.\tspeed now 6.41\tEMA speed 7.36\n",
      "2018-07-05T22:09:12PDT - re_iter.py - INFO - OUT yielded 115000 items.\tspeed now 5.95\tEMA speed 7.22\n",
      "2018-07-05T22:20:53PDT - re_iter.py - INFO - OUT yielded 120000 items.\tspeed now 7.13\tEMA speed 7.21\n",
      "2018-07-05T22:32:37PDT - re_iter.py - INFO - OUT yielded 125000 items.\tspeed now 7.10\tEMA speed 7.20\n",
      "2018-07-05T22:51:52PDT - re_iter.py - INFO - OUT yielded 130000 items.\tspeed now 4.33\tEMA speed 6.91\n",
      "2018-07-05T23:12:42PDT - re_iter.py - INFO - OUT yielded 135000 items.\tspeed now 4.00\tEMA speed 6.62\n",
      "2018-07-05T23:30:24PDT - re_iter.py - INFO - OUT yielded 140000 items.\tspeed now 4.71\tEMA speed 6.43\n",
      "2018-07-05T23:37:51PDT - re_iter.py - INFO - reMap:\tFinished iter number 2\ttotal items: 5\ttotal time: 21958.2 sec\n",
      "2018-07-05T23:37:51PDT - re_iter.py - INFO - chain rows from files:\tFinished iter number 2\ttotal items: 284570\ttotal time: 21958.2 sec\n",
      "2018-07-05T23:39:38PDT - re_iter.py - INFO - reMap:\tFinished iter number 2\ttotal items: 6\ttotal time: 22064.3 sec\n",
      "2018-07-05T23:39:38PDT - re_iter.py - INFO - chain rows from files:\tFinished iter number 2\ttotal items: 285140\ttotal time: 22064.3 sec\n",
      "2018-07-05T23:39:38PDT - re_iter.py - INFO - reGenerate:\tFinished iter number 1\ttotal items: 142570\ttotal time: 22064.4 sec\n",
      "2018-07-05T23:39:38PDT - re_iter.py - INFO - OUT:\tFinished iter number 1\ttotal items: 142570\ttotal time: 22064.4 sec\n",
      "2018-07-05T23:39:38PDT - re_iter.py - INFO - reMap:\tFinished iter number 1\ttotal items: 142570\ttotal time: 22064.4 sec\n",
      "2018-07-05T23:39:38PDT - re_iter.py - INFO - Disk Cache:\tSaved iterable to 4476141b-8009-4d46-a7c7-d8707b251d1c, size 219,687,347\n",
      "2018-07-05T23:39:38PDT - re_iter.py - INFO - Disk Cache:\tFinished iter number 1\ttotal items: 142570\ttotal time: 22064.4 sec\n",
      "2018-07-05T23:39:39PDT - gensim_models.py - INFO - Final raw dictionary: Dictionary(100000 unique tokens: ['access', 'administration', 'advocate', 'ally', 'appeal']...)\n",
      "2018-07-05T23:39:39PDT - gensim_models.py - INFO - Final dictionary: Dictionary(10000 unique tokens: ['access', 'advocate', 'ally', 'appeal', 'appropriation']...)\n"
     ]
    }
   ],
   "source": [
    "gensim_dict = GensimDictionary({\n",
    "    'no_below_raw': 0,\n",
    "    'no_above_raw': 1.,\n",
    "    'max_n_raw': 100000,\n",
    "    'no_below': 10,\n",
    "    'no_above': 0.1,\n",
    "    'max_n': 10000,\n",
    "    'dict_filter_every': 50000,\n",
    "})\n",
    "\n",
    "gensim_dict = gensim_dict.train(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert tokens into Bag-of-Words representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = gensim_dict.itransform(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate and train gensim LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-05T23:39:39PDT - gensim_models.py - INFO - Init gensim LDA with params:\n",
      "{'num_topics': 100}\n",
      "2018-07-05T23:39:39PDT - re_iter.py - INFO - GensimDictionary:\tStart iter number 1\n",
      "2018-07-05T23:39:39PDT - re_iter.py - INFO - Disk Cache:\tStart iter number 2\n",
      "2018-07-05T23:39:39PDT - re_iter.py - INFO - Disk Cache:\tReading saved iterable from 4476141b-8009-4d46-a7c7-d8707b251d1c\n",
      "2018-07-05T23:39:57PDT - re_iter.py - INFO - Disk Cache:\tFinished iter number 2\ttotal items: 142570\ttotal time: 17.6 sec\n",
      "2018-07-05T23:39:57PDT - re_iter.py - INFO - GensimDictionary:\tFinished iter number 1\ttotal items: 142570\ttotal time: 17.6 sec\n",
      "2018-07-05T23:39:57PDT - re_iter.py - INFO - GensimDictionary:\tStart iter number 2\n",
      "2018-07-05T23:39:57PDT - re_iter.py - INFO - Disk Cache:\tStart iter number 3\n",
      "2018-07-05T23:39:57PDT - re_iter.py - INFO - Disk Cache:\tReading saved iterable from 4476141b-8009-4d46-a7c7-d8707b251d1c\n",
      "/Users/merekhinsky/miniconda3/lib/python3.6/site-packages/gensim/models/ldamodel.py:775: RuntimeWarning: divide by zero encountered in log\n",
      "  diff = np.log(self.expElogbeta)\n",
      "2018-07-05T23:41:04PDT - re_iter.py - INFO - Disk Cache:\tFinished iter number 3\ttotal items: 142570\ttotal time: 67.2 sec\n",
      "2018-07-05T23:41:04PDT - re_iter.py - INFO - GensimDictionary:\tFinished iter number 2\ttotal items: 142570\ttotal time: 67.2 sec\n"
     ]
    }
   ],
   "source": [
    "g_lda = GensimLDA(lda_params={'num_topics': 100}, id2word=gensim_dict.state.model.id2token)\n",
    "g_lda = g_lda.train(bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert BOW representation to LDA sparse vectors and join with original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = g_lda.itransform(bow)\n",
    "\n",
    "# zip together with original records\n",
    "final = ReZip(records, vectors)\n",
    "\n",
    "# and add vectors to records\n",
    "final = ReMap(lambda x: {'lda': x[1], **x[0]}, final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-05T23:41:31PDT - re_iter.py - INFO - reMap:\tStart iter number 1\n",
      "2018-07-05T23:41:31PDT - re_iter.py - INFO - re-zip:\tStart iter number 1\n",
      "2018-07-05T23:41:31PDT - re_iter.py - INFO - chain rows from files:\tStart iter number 3\n",
      "2018-07-05T23:41:31PDT - re_iter.py - INFO - reMap:\tStart iter number 3\n",
      "2018-07-05T23:41:31PDT - re_iter.py - INFO - GensimLDA:\tStart iter number 1\n",
      "2018-07-05T23:41:31PDT - re_iter.py - INFO - GensimDictionary:\tStart iter number 3\n",
      "2018-07-05T23:41:31PDT - re_iter.py - INFO - Disk Cache:\tStart iter number 4\n",
      "2018-07-05T23:41:31PDT - re_iter.py - INFO - Disk Cache:\tReading saved iterable from 4476141b-8009-4d46-a7c7-d8707b251d1c\n",
      "2018-07-05T23:45:07PDT - re_iter.py - INFO - reMap:\tFinished iter number 3\ttotal items: 3\ttotal time: 215.9 sec\n",
      "2018-07-05T23:45:07PDT - re_iter.py - INFO - chain rows from files:\tFinished iter number 3\ttotal items: 142570\ttotal time: 215.9 sec\n",
      "2018-07-05T23:45:07PDT - re_iter.py - INFO - re-zip:\tFinished iter number 1\ttotal items: 142570\ttotal time: 215.9 sec\n",
      "2018-07-05T23:45:07PDT - re_iter.py - INFO - reMap:\tFinished iter number 1\ttotal items: 142570\ttotal time: 215.9 sec\n"
     ]
    }
   ],
   "source": [
    "# trigger all these final calculations\n",
    "final = [_ for _ in final]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lda': [(14, 0.07707414031028748),\n",
       "  (18, 0.48351725935935974),\n",
       "  (21, 0.2209157645702362),\n",
       "  (33, 0.15834416449069977),\n",
       "  (55, 0.05055266246199608)],\n",
       " '': '146023',\n",
       " 'id': '218073',\n",
       " 'title': 'What U.S. Muslims fear from Trump',\n",
       " 'publication': 'Washington Post',\n",
       " 'author': 'Naureen Shah',\n",
       " 'date': '2016-12-30',\n",
       " 'year': '2016.0',\n",
       " 'month': '12.0',\n",
       " 'url': 'https://web.archive.org/web/20161231004909/https://www.washingtonpost.com/opinions/gen-kelly-has-talked-about-human-rights-will-trump-listen/2016/12/30/ebabbcea-c928-11e6-bf4b-2c064d32a4bf_story.html\\n',\n",
       " 'content': '   Naureen Shah is director of security and human rights at Amnesty International USA.    The Obama administration is dismantling a homeland security program created to track immigrants from   countries in an attempt to prevent   Donald Trump from fulfilling his campaign promise to create a Muslim registry. As an American Muslim and human rights advocate, I am hoping against hope that retired Gen. John F. Kelly, the homeland security secretary nominee, will not reassemble the program. Kelly is not an obvious champion of human rights. As head of U. S. Southern Command, Kelly oversaw Guantanamo, where he frequently dismissed human rights concerns. Dozens of people languished in detention without charge, and many were   after going on hunger strikes. But he could be our best hope in the Trump administration.  While at Southern Command, Kelly invited critiques from human rights groups. Every year, he asked Amnesty International and other organizations to join him for a frank roundtable discussion. After one meeting, he took me aside to explain his point of view and hear me out. Dialogue and decency: In today’s   political climate, these are as rare as unicorns. And they matter. If I could talk to Kelly today, I think he’d listen. I would tell him that people are afraid. Activists worry that if they speak out, the government could retaliate or put them under surveillance. Trump’s idle tweets about stripping people of citizenship for   are eerily reminiscent of foreign dictators threatening to jail people for peaceful dissent. People like me  —   ordinary Americans with Muslim names and ancestry from   countries  —   fear being put on a watchlist, barred entry into the United States, even banned because of who we are. Many people  —   African Americans, Jewish Americans, Muslim Americans, immigrants who’ve spent most of their adult lives here  —   spent the holidays swapping stories of threats, harassment and even violent attacks by fellow Americans who think the election has given them license to act on hatred. I believe Kelly would listen to me, not because he has ever agreed with me, but because he has been willing to talk. And a top national security official who values dialogue over diatribes is what we need to put the brakes on Trump’s most frightening counterterrorism proposals.  Kelly must not revive NSEERS (the National Security   Registration System). He is a smart man  —   he knows that a special registry would make for bad counterterrorism. Law enforcement officials need people to trust them and tip them off, not fear and avoid them. A special registration would send shockwaves through immigrant communities, inviting uncertainty and anxiety, more fear of law enforcement and less safety.   Unlike some of Trump’s other national security advisers, though, Kelly does not appear to be infected with bizarrely virulent   prejudice. And more than anything, the proposed Muslim ban, internment and special registration proposals are about prejudice  —   not safety. They cater to bigotry and fear, which fly in the face of our country’s most precious values. They tear at the seams of our commonality by implying that only some people are included in the ideals of liberty and justice. They drive people even farther apart from each other, after an election that already has left us fragmented.  It may be naive to think that Kelly  —   or anyone else in the Trump administration  —   would risk his career to stand in the way of   rights proposals. But many of these proposals, only a short while ago, would have been considered unimaginable. They threaten to return this country to the grimmest chapters of our history, like the mass imprisonment of U. S. citizens and noncitizens of Japanese descent. They are the stuff of dystopic novels, of nightmares. Kelly could reject the bigotry and irrationality of these proposals, and senators at his confirmation hearing should call on him to do so. The next secretary of homeland security can refuse to carry forward Trump’s   policies, and also decline to cooperate with the FBI or any other agency on the surveillance of activists, immigrants or particular communities. Perhaps most important, the general could use his position to counteract advisers who may tell Trump that he needn’t listen to the millions of Americans who support human rights and civil liberties. Kelly was always willing to listen to the human rights community. Now, I’m hoping that the   will listen to him.   Read more on this issue:   Josh Rogin: A workable Homeland Security plan for Trump   Carter and Schulman: Trump is surrounding himself with generals. That’s dangerous.   The Post’s View: Trump has made some dangerous appointments   The Post’s View: Trump’s election threatens human rights around the world   Jackson Diehl: Trump’s coming war against Islam  '}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final[-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.045*\"immigration\" + 0.036*\"immigrant\" + 0.019*\"border\" + 0.015*\"migrant\" + 0.012*\"deportation\" + 0.011*\"crime\" + 0.011*\"enforcement\" + 0.008*\"asylum\" + 0.008*\"citizen\" + 0.007*\"refugee\"\n",
      "0.020*\"rule\" + 0.020*\"bill\" + 0.016*\"judge\" + 0.015*\"ban\" + 0.011*\"ruling\" + 0.010*\"legislation\" + 0.010*\"governor\" + 0.008*\"lawmaker\" + 0.008*\"justice\" + 0.007*\"regulation\"\n",
      "0.017*\"march\" + 0.013*\"protest\" + 0.012*\"town\" + 0.012*\"hall\" + 0.012*\"senator\" + 0.012*\"activist\" + 0.010*\"corruption\" + 0.008*\"protester\" + 0.008*\"crowd\" + 0.007*\"dinner\"\n"
     ]
    }
   ],
   "source": [
    "print(g_lda.state.model.print_topic(18))\n",
    "print(g_lda.state.model.print_topic(21))\n",
    "print(g_lda.state.model.print_topic(33))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
